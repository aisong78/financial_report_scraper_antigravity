import streamlit as st
import pandas as pd
import akshare as ak
import plotly.graph_objects as go
import sqlite3
import json
from datetime import datetime
from pathlib import Path
from fetchers.a_share import AShareFetcher
from fetchers.hk_share import HKShareFetcher
from calculator import FinancialCalculator

# æ•°æ®åº“è·¯å¾„
DB_PATH = Path(__file__).parent / "finance.db"

# åˆå§‹åŒ–å·¥å…·
# åˆå§‹åŒ–å·¥å…·
# fetcher = AShareFetcher() (å·²ç§»é™¤å…¨å±€å®ä¾‹)
calculator = FinancialCalculator()

def get_fetcher(stock_code):
    if len(stock_code) == 5 and stock_code.isdigit():
        return HKShareFetcher()
    return AShareFetcher()

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="Antigravity æ™ºèƒ½è´¢æŠ¥åˆ†æ",
    page_icon="ğŸš€",
    layout="wide"
)

def get_stock_data(stock_code):
    """
    è·å–è‚¡ç¥¨æ•°æ®ï¼šå…ˆæŸ¥åº“ï¼Œæ²¡æœ‰åˆ™æŠ“å–
    """
    conn = sqlite3.connect(DB_PATH)
    
    # 1. æ£€æŸ¥æ•°æ®åº“æ˜¯å¦æœ‰æ•°æ®
    df = pd.read_sql(f"SELECT * FROM financial_indicators_derived WHERE stock_code='{stock_code}' ORDER BY report_period DESC LIMIT 1", conn)
    
    if df.empty:
        st.info(f"æœ¬åœ°æ—  {stock_code} æ•°æ®ï¼Œæ­£åœ¨ä»äº‘ç«¯æŠ“å– (2010-2024)...")
        fetcher = get_fetcher(stock_code)
        success = fetcher.fetch_financial_data(stock_code)
        if success:
            calculator.calculate_indicators(stock_code)
            # é‡æ–°è¯»å–
            df = pd.read_sql(f"SELECT * FROM financial_indicators_derived WHERE stock_code='{stock_code}' ORDER BY report_period DESC LIMIT 1", conn)
        else:
            st.error("æŠ“å–å¤±è´¥ï¼Œè¯·æ£€æŸ¥è‚¡ç¥¨ä»£ç æ˜¯å¦æ­£ç¡®ã€‚")
            return None, None
            
    conn.close()
    
    # è·å–å®æ—¶è¡Œæƒ…ï¼ˆç”¨äºå±•ç¤ºå¸‚å€¼ç­‰ï¼‰
    try:
        stock_info = ak.stock_individual_info_em(symbol=stock_code)
        info_dict = dict(zip(stock_info['item'], stock_info['value']))
    except:
        info_dict = {}
        
    return info_dict, df.iloc[0] if not df.empty else None

def analyze_gap(metrics, framework_type="value"):
    """
    å·®è·åˆ†æå¼•æ“
    """
    results = []
    score = 0
    total_score = 0
    
    def safe_get(val, default=0):
        return val if val is not None else default
        
    def format_val(val, is_percent=True):
        if val is None: return "-"
        return f"{val:.2f}%" if is_percent else f"{val/1e8:.2f} äº¿"

    if framework_type == "ä»·å€¼æŠ•èµ„ (å·´è²ç‰¹)":
        # 1. ROE
        target = 15
        actual = metrics['roe']
        if actual is not None:
            gap = actual - target
            status = "âœ… è¾¾æ ‡" if gap >= 0 else "âŒ æœªè¾¾æ ‡"
            score += 100 if gap >= 0 else (50 if gap > -5 else 0)
        else:
            gap = 0
            status = "âš ï¸ æ•°æ®ç¼ºå¤±"
            
        results.append({
            "æŒ‡æ ‡": "ROE (å‡€èµ„äº§æ”¶ç›Šç‡)",
            "æ ‡å‡†": f"> {target}%",
            "å®é™…": format_val(actual),
            "å·®è·": f"{gap:+.2f}%" if actual is not None else "-",
            "çŠ¶æ€": status,
            "è§£è¯»": "ç›ˆåˆ©èƒ½åŠ›å¼ºåŠ²" if actual is not None and gap >= 0 else "ç›ˆåˆ©èƒ½åŠ›è¾ƒå¼±æˆ–æ•°æ®ç¼ºå¤±"
        })
        
        # 2. æ¯›åˆ©ç‡
        target = 40
        actual = metrics['gross_margin']
        if actual is not None:
            gap = actual - target
            status = "âœ… è¾¾æ ‡" if gap >= 0 else "âš ï¸ åä½"
        else:
            gap = 0
            status = "âš ï¸ æ•°æ®ç¼ºå¤±"
            
        results.append({
            "æŒ‡æ ‡": "æ¯›åˆ©ç‡",
            "æ ‡å‡†": f"> {target}%",
            "å®é™…": format_val(actual),
            "å·®è·": f"{gap:+.2f}%" if actual is not None else "-",
            "çŠ¶æ€": status,
            "è§£è¯»": "äº§å“å…·å¤‡å®šä»·æƒ" if actual is not None and gap >= 0 else "ç«äº‰æ¿€çƒˆæˆ–æ•°æ®ç¼ºå¤±"
        })
        
        # 3. è´Ÿå€ºç‡
        target = 60
        actual = metrics['debt_to_asset']
        if actual is not None:
            gap = target - actual # è¶Šä½è¶Šå¥½
            status = "âœ… è¾¾æ ‡" if gap >= 0 else "âŒ é£é™©"
        else:
            gap = 0
            status = "âš ï¸ æ•°æ®ç¼ºå¤±"
            
        results.append({
            "æŒ‡æ ‡": "èµ„äº§è´Ÿå€ºç‡",
            "æ ‡å‡†": f"< {target}%",
            "å®é™…": format_val(actual),
            "å·®è·": f"{gap:+.2f}% (å®‰å…¨ç©ºé—´)" if actual is not None else "-",
            "çŠ¶æ€": status,
            "è§£è¯»": "è´¢åŠ¡ç»“æ„å¥åº·" if actual is not None and gap >= 0 else "æ æ†è¿‡é«˜æˆ–æ•°æ®ç¼ºå¤±"
        })
        
        # 4. è‡ªç”±ç°é‡‘æµ
        actual = metrics['fcf']
        if actual is not None:
            status = "âœ… æ­£å‘" if actual > 0 else "âŒ è´Ÿå‘"
        else:
            status = "âš ï¸ æ•°æ®ç¼ºå¤±"
            
        results.append({
            "æŒ‡æ ‡": "è‡ªç”±ç°é‡‘æµ",
            "æ ‡å‡†": "> 0",
            "å®é™…": format_val(actual, is_percent=False),
            "å·®è·": "-",
            "çŠ¶æ€": status,
            "è§£è¯»": "å…·å¤‡é€ è¡€èƒ½åŠ›" if actual is not None and actual > 0 else "æŒç»­çƒ§é’±æˆ–æ•°æ®ç¼ºå¤±"
        })

    return results

# --- ç•Œé¢é€»è¾‘ ---

# ä¾§è¾¹æ 
with st.sidebar:
    st.title("ğŸš€ æ§åˆ¶å°")
    
    # ç®€å•ç›´æ¥çš„è‚¡ç¥¨ä»£ç è¾“å…¥
    if 'stock_code' not in st.session_state:
        st.session_state['stock_code'] = '01810' # é»˜è®¤å°ç±³

    def update_code():
        st.session_state['stock_code'] = st.session_state.code_input

    selected_stock = st.text_input(
        "è¾“å…¥è‚¡ç¥¨ä»£ç ", 
        value=st.session_state['stock_code'],
        key='code_input',
        on_change=update_code,
        help="è¾“å…¥ä»£ç åå›è½¦ï¼Œå¦‚ 01810, 600519"
    )
    
    # ç¡®ä¿åŒæ­¥
    st.session_state['stock_code'] = selected_stock
    
    st.markdown("---")
    st.subheader("æ•°æ®ç­›é€‰")
    report_type = st.selectbox("æŠ¥å‘Šç±»å‹", ["å…¨éƒ¨", "å¹´æŠ¥ (A)", "ä¸‰å­£æŠ¥ (Q3)", "åŠå¹´æŠ¥ (S1)", "ä¸€å­£æŠ¥ (Q1)"], index=0)
    
    if st.button("å¼ºåˆ¶æ›´æ–°æ•°æ®"):
        fetcher = get_fetcher(selected_stock)
        fetcher.fetch_financial_data(selected_stock)
        calculator.calculate_indicators(selected_stock)
        # æ¸…é™¤ç¼“å­˜ä»¥é‡æ–°åŠ è½½æ•°æ®
        if 'df_raw' in st.session_state:
            del st.session_state.df_raw
        st.success("å·²æ›´æ–°ï¼è¯·åˆ·æ–°é¡µé¢ã€‚")
        st.rerun()

    st.markdown("---")
    with st.expander("âœï¸ ä¿®æ­£æ•°æ® (Manual Override)"):
        st.caption("æ‰‹åŠ¨ä¿®æ”¹æ•°æ®å°†é”å®šè¯¥è®°å½•ï¼Œé˜²æ­¢è¢«è‡ªåŠ¨è¦†ç›–ã€‚")
        
        # è·å–å½“å‰è‚¡ç¥¨çš„æ‰€æœ‰æŠ¥å‘ŠæœŸ
        conn = sqlite3.connect(DB_PATH)
        periods = pd.read_sql(f"SELECT report_period FROM financial_reports_raw WHERE stock_code='{selected_stock}' ORDER BY report_period DESC", conn)['report_period'].tolist()
        conn.close()
        
        edit_period = st.selectbox("é€‰æ‹©æŠ¥å‘ŠæœŸ", periods)
        
        # å­—æ®µåˆ—è¡¨
        edit_fields = {
            'revenue': 'è¥ä¸šæ”¶å…¥',
            'net_income_parent': 'å½’æ¯å‡€åˆ©æ¶¦',
            'total_assets': 'æ€»èµ„äº§',
            'total_equity': 'è‚¡ä¸œæƒç›Š',
            'gross_profit': 'æ¯›åˆ©',
            'net_income': 'å‡€åˆ©æ¶¦',
            'cfo_net': 'ç»è¥ç°é‡‘æµå‡€é¢',
            'income_tax_expenses': 'æ‰€å¾—ç¨è´¹ç”¨',
            'current_assets': 'æµåŠ¨èµ„äº§',
            'non_current_assets': 'éæµåŠ¨èµ„äº§',
            'intangible_assets': 'æ— å½¢èµ„äº§',
            'current_liabilities': 'æµåŠ¨è´Ÿå€º',
            'non_current_liabilities': 'éæµåŠ¨è´Ÿå€º',
            'share_capital': 'è‚¡æœ¬',
            'retained_earnings': 'æœªåˆ†é…åˆ©æ¶¦',
            'net_cash_flow': 'ç°é‡‘å‡€å¢åŠ é¢'
        }
        edit_field_key = st.selectbox("é€‰æ‹©å­—æ®µ", list(edit_fields.keys()), format_func=lambda x: f"{edit_fields[x]} ({x})")
        
        # è·å–å½“å‰å€¼
        current_val = 0.0
        if edit_period:
            conn = sqlite3.connect(DB_PATH)
            cursor = conn.cursor()
            cursor.execute(f"SELECT {edit_field_key} FROM financial_reports_raw WHERE stock_code=? AND report_period=?", (selected_stock, edit_period))
            row = cursor.fetchone()
            if row and row[0] is not None:
                current_val = float(row[0])
            conn.close()
            
        new_val = st.number_input("æ–°å€¼ (å•ä½: å…ƒ)", value=current_val, format="%.2f")
        st.caption(f"å½“å‰å€¼: {current_val/1e8:.2f} äº¿")
        
        if st.button("ä¿å­˜å¹¶é”å®š"):
            try:
                conn = sqlite3.connect(DB_PATH)
                cursor = conn.cursor()
                # æ›´æ–°æ•°æ®å¹¶é”å®š
                cursor.execute(f'''
                    UPDATE financial_reports_raw 
                    SET {edit_field_key} = ?, is_locked = 1, data_quality = 'MANUAL'
                    WHERE stock_code = ? AND report_period = ?
                ''', (new_val, selected_stock, edit_period))
                conn.commit()
                conn.close()
                
                # é‡æ–°è®¡ç®—æŒ‡æ ‡
                calculator.calculate_indicators(selected_stock)
                
                # æ¸…é™¤ç¼“å­˜
                if 'df_raw' in st.session_state:
                    del st.session_state.df_raw
                
                st.success(f"å·²æ›´æ–° {edit_period} çš„ {edit_fields[edit_field_key]}ï¼")
                st.rerun()
            except Exception as e:
                st.error(f"æ›´æ–°å¤±è´¥: {e}")

# ä¸»ç•Œé¢
st.title(f"ğŸ“Š {selected_stock} è´¢åŠ¡æ•°æ®å…¨æ™¯")

# è·å–æ•°æ®å‡½æ•°
def get_all_history(stock_code):
    conn = sqlite3.connect(DB_PATH)
    df_raw = pd.read_sql(f"SELECT * FROM financial_reports_raw WHERE stock_code='{stock_code}' ORDER BY report_period DESC", conn)
    df_derived = pd.read_sql(f"SELECT * FROM financial_indicators_derived WHERE stock_code='{stock_code}' ORDER BY report_period DESC", conn)
    conn.close()
    return df_raw, df_derived

# åˆå§‹åŒ– session_state
if 'df_raw' not in st.session_state:
    st.session_state.df_raw = pd.DataFrame()
if 'df_derived' not in st.session_state:
    st.session_state.df_derived = pd.DataFrame()

# åŠ è½½æŒ‰é’®é€»è¾‘
if st.button("åŠ è½½/åˆ·æ–°æ•°æ®", type="primary"):
    with st.spinner("æ­£åœ¨æå–å†å²æ•°æ®..."):
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æŠ“å–
        conn = sqlite3.connect(DB_PATH)
        check_df = pd.read_sql(f"SELECT id FROM financial_reports_raw WHERE stock_code='{selected_stock}' LIMIT 1", conn)
        conn.close()
        
        if check_df.empty:
            st.info("æœ¬åœ°æ— æ•°æ®ï¼Œæ­£åœ¨äº‘ç«¯æŠ“å–...")
            fetcher = get_fetcher(selected_stock)
            fetcher.fetch_financial_data(selected_stock)
            calculator.calculate_indicators(selected_stock)
            
        raw, derived = get_all_history(selected_stock)
        st.session_state.df_raw = raw
        st.session_state.df_derived = derived
        st.success("æ•°æ®å·²åŠ è½½ï¼")

# æ•°æ®å±•ç¤ºé€»è¾‘ (åªè¦ session_state æœ‰æ•°æ®å°±æ˜¾ç¤º)
if not st.session_state.df_raw.empty:
    df_raw = st.session_state.df_raw
    df_derived = st.session_state.df_derived

    # --- 1. ç­›é€‰å™¨ (ç§»è‡³ä¸»ç•Œé¢) ---
    st.markdown("### ğŸ› ï¸ æ•°æ®ç­›é€‰")
    col_filter, col_empty = st.columns([1, 3])
    with col_filter:
        report_type = st.selectbox("åªçœ‹å“ªç§æŠ¥è¡¨ï¼Ÿ", ["å…¨éƒ¨", "å¹´æŠ¥ (A)", "ä¸‰å­£æŠ¥ (Q3)", "åŠå¹´æŠ¥ (S1)", "ä¸€å­£æŠ¥ (Q1)"], index=0)

    # --- 2. æ•°æ®é¢„å¤„ç†ï¼šç”Ÿæˆ '2023A' æ ¼å¼çš„åˆ—å ---
    # ç»Ÿä¸€è½¬æ¢ä¸º datetime å¯¹è±¡ï¼Œå¤„ç†å¯èƒ½çš„å­—ç¬¦ä¸²æˆ– Timestamp
    df_raw['report_period_dt'] = pd.to_datetime(df_raw['report_period'])
    # --- 2. æ•°æ®é¢„å¤„ç†ï¼šç”Ÿæˆ '2023A' æ ¼å¼çš„åˆ—å ---
    # ç»Ÿä¸€è½¬æ¢ä¸º datetime å¯¹è±¡
    df_raw['report_period_dt'] = pd.to_datetime(df_raw['report_period'])
    df_derived['report_period_dt'] = pd.to_datetime(df_derived['report_period'])
    
    # å…³é”®ä¿®å¤ï¼šdf_derived è¡¨é‡Œæ²¡æœ‰ report_type å­—æ®µï¼Œéœ€è¦ä» df_raw åˆå¹¶è¿‡æ¥
    # æˆ–è€…ç®€å•å¤„ç†ï¼šç›´æ¥æ ¹æ® report_period åŒ¹é…
    # è¿™é‡Œæˆ‘ä»¬å‡è®¾ä¸¤è€…è¡Œæ•°ä¸€è‡´ä¸”é¡ºåºä¸€è‡´ï¼ˆå› ä¸ºéƒ½æ˜¯ ORDER BY report_period DESCï¼‰
    # æ›´ç¨³å¦¥çš„åšæ³•æ˜¯ merge
    if 'report_type' not in df_derived.columns:
        temp_map = df_raw[['report_period', 'report_type']].drop_duplicates()
        df_derived = pd.merge(df_derived, temp_map, on='report_period', how='left')

    def generate_name(row):
        try:
            year = row['report_period_dt'].year
            rtype = row['report_type']
            return f"{year}{rtype}"
        except:
            return str(row['report_period'])

    df_raw['report_name'] = df_raw.apply(generate_name, axis=1)
    df_derived['report_name'] = df_derived.apply(generate_name, axis=1)
        
    # è°ƒè¯•ï¼šåœ¨ä¾§è¾¹æ æ˜¾ç¤ºæ•°æ®çŠ¶æ€
    with st.sidebar:
        st.markdown("---")
        st.caption("ğŸ”§ è°ƒè¯•ä¿¡æ¯")
        st.write(f"åŸå§‹è¡Œæ•°: {len(df_raw)}")
        st.write(f"åŒ…å«ç±»å‹: {df_raw['report_type'].unique()}")

    # --- 3. æ‰§è¡Œç­›é€‰ ---
    type_map = {"å¹´æŠ¥ (A)": "A", "ä¸‰å­£æŠ¥ (Q3)": "Q3", "åŠå¹´æŠ¥ (S1)": "S1", "ä¸€å­£æŠ¥ (Q1)": "Q1"}
    
    if report_type != "å…¨éƒ¨":
        target_type = type_map[report_type]
        # ä¸¥æ ¼ç­›é€‰
        df_raw = df_raw[df_raw['report_type'] == target_type]
        df_derived = df_derived[df_derived['report_type'] == target_type]
        
        if df_raw.empty:
            st.error(f"ç­›é€‰ '{target_type}' åæ•°æ®ä¸ºç©ºï¼è¯·æ£€æŸ¥æ•°æ®æºã€‚")
    
    # --- 3.5 æ•°æ®è´¨é‡ç»Ÿè®¡ ---
    if 'data_quality' in df_raw.columns:
        st.markdown("### ğŸ“Š æ•°æ®è´¨é‡æ¦‚è§ˆ")
        col1, col2, col3 = st.columns(3)
        
        verified_count = len(df_raw[df_raw['data_quality'] == 'VERIFIED'])
        unverified_count = len(df_raw[df_raw['data_quality'] == 'UNVERIFIED'])
        conflict_count = len(df_raw[df_raw['data_quality'] == 'CONFLICT'])
        
        with col1:
            st.metric("âœ… å·²éªŒè¯", verified_count)
        with col2:
            st.metric("âš ï¸ æœªéªŒè¯", unverified_count)
        with col3:
            st.metric("âŒ æ•°æ®å†²çª", conflict_count)
        
        # è¯¦ç»†éªŒè¯çŠ¶æ€ï¼ˆå¯å±•å¼€ï¼‰
        with st.expander("ğŸ“‹ æŸ¥çœ‹è¯¦ç»†éªŒè¯çŠ¶æ€"):
            # æŒ‰æŠ¥å‘ŠæœŸåˆ†ç»„æ˜¾ç¤º
            # ç¡®ä¿ validation_details å­˜åœ¨
            cols_to_use = ['report_period', 'report_type', 'data_quality']
            if 'validation_details' in df_raw.columns:
                cols_to_use.append('validation_details')
                
            quality_details = df_raw[cols_to_use].copy()
            quality_details['report_name'] = quality_details.apply(
                lambda row: f"{row['report_period'][:4]}{row['report_type']}", axis=1
            )
            
            # æ˜¾ç¤ºå·²éªŒè¯çš„
            if verified_count > 0:
                st.markdown("**âœ… å·²éªŒè¯çš„æŠ¥å‘Šï¼š**")
                verified = quality_details[quality_details['data_quality'] == 'VERIFIED']
                st.write(", ".join(verified['report_name'].tolist()))
            
            # æ˜¾ç¤ºæœ‰å†²çªçš„
            if conflict_count > 0:
                st.markdown("**âŒ æ•°æ®å†²çªçš„æŠ¥å‘Šï¼š**")
                conflicts = quality_details[quality_details['data_quality'] == 'CONFLICT']
                
                for _, row in conflicts.iterrows():
                    st.markdown(f"**{row['report_name']}**")
                    
                    # è§£æ validation_details JSON
                    if 'validation_details' in row and row['validation_details']:
                        try:
                            details = json.loads(row['validation_details'])
                            # åªæ˜¾ç¤ºå†²çªçš„å­—æ®µ
                            conflict_fields = {k: v for k, v in details.items() if v.get('status') == 'CONFLICT'}
                            
                            if conflict_fields:
                                for field, info in conflict_fields.items():
                                    field_name_map = {
                                        'revenue': ('è¥ä¸šæ”¶å…¥', 'åˆ©æ¶¦è¡¨'),
                                        'net_income_parent': ('å½’æ¯å‡€åˆ©æ¶¦', 'åˆ©æ¶¦è¡¨'),
                                        'total_assets': ('æ€»èµ„äº§', 'èµ„äº§è´Ÿå€ºè¡¨'),
                                        'total_equity': ('è‚¡ä¸œæƒç›Š', 'èµ„äº§è´Ÿå€ºè¡¨')
                                    }
                                    field_info = field_name_map.get(field, (field, 'æœªçŸ¥è¡¨'))
                                    field_cn = field_info[0]
                                    table_name = field_info[1]
                                    
                                    st.warning(
                                        f"âš ï¸ **{field_cn}** ({table_name}): "
                                        f"AkShare={info['akshare']}äº¿, "
                                        f"PDF={info['pdf']}äº¿, "
                                        f"å·®å¼‚={info['diff_pct']}%"
                                    )
                            else:
                                st.caption("ï¼ˆè¯¦æƒ…ç¼ºå¤±ï¼Œè¯·é‡æ–°éªŒè¯ï¼‰")
                        except Exception as e:
                            st.caption(f"ï¼ˆè§£æè¯¦æƒ…å¤±è´¥: {e}ï¼‰")
                    else:
                        st.caption("ï¼ˆæ— è¯¦ç»†ä¿¡æ¯ï¼‰")
            
            # æ˜¾ç¤ºæœªéªŒè¯çš„ï¼ˆåªæ˜¾ç¤ºå‰10ä¸ªï¼Œé¿å…å¤ªé•¿ï¼‰
            if unverified_count > 0:
                st.markdown(f"**âš ï¸ æœªéªŒè¯çš„æŠ¥å‘Šï¼ˆå…±{unverified_count}ä¸ªï¼‰ï¼š**")
                unverified = quality_details[quality_details['data_quality'] == 'UNVERIFIED']
                unverified_list = unverified['report_name'].tolist()
                if len(unverified_list) > 10:
                    st.write(", ".join(unverified_list[:10]) + f" ...ç­‰{len(unverified_list)}ä¸ª")
                else:
                    st.write(", ".join(unverified_list))
                
                st.caption("ğŸ’¡ æç¤ºï¼šæœªéªŒè¯çš„æ•°æ®ç¼ºå°‘å¯¹åº”çš„PDFæ–‡ä»¶ï¼Œéœ€è¦å…ˆä¸‹è½½è´¢æŠ¥åŸæ–‡æ‰èƒ½éªŒè¯ã€‚")
        
        st.markdown("---")
    
    # --- 4. è¾…åŠ©å‡½æ•°ï¼šè½¬ç½®è¡¨æ ¼ ---
    def transpose_df(df, index_col='report_name', exclude_cols=['id', 'stock_code', 'currency', 'publish_date', 'report_period', 'report_type', 'report_period_dt', 'data_quality', 'validation_details', 'is_locked']):
        if df.empty: return pd.DataFrame()
        # ç¡®ä¿ç´¢å¼•å”¯ä¸€
        df = df.drop_duplicates(subset=[index_col])
        # è®¾ç½®ç´¢å¼•
        df = df.set_index(index_col)
        # å‰”é™¤æ— å…³åˆ—
        cols = [c for c in df.columns if c not in exclude_cols]
        df = df[cols]
        # è½¬ç½®
        return df.T

    # --- 5. å­—æ®µæ˜ å°„å­—å…¸ (è¡¥å…¨) ---
    field_map = {
        # è¡ç”ŸæŒ‡æ ‡
        'gross_margin': 'æ¯›åˆ©ç‡ (Gross Margin) [%]',
        'net_margin': 'å‡€åˆ©ç‡ (Net Margin) [%]',
        'roe': 'å‡€èµ„äº§æ”¶ç›Šç‡ (ROE) [%]',
        'roa': 'æ€»èµ„äº§æ”¶ç›Šç‡ (ROA) [%]',
        'revenue_yoy': 'è¥æ”¶å¢é•¿ç‡ (YoY) [%]',
        'net_profit_yoy': 'å‡€åˆ©å¢é•¿ç‡ (YoY) [%]',
        'debt_to_asset': 'èµ„äº§è´Ÿå€ºç‡ [%]',
        'current_ratio': 'æµåŠ¨æ¯”ç‡',
        'inventory_turnover_days': 'å­˜è´§å‘¨è½¬å¤©æ•° [å¤©]',
        'receivables_turnover_days': 'åº”æ”¶è´¦æ¬¾å‘¨è½¬å¤©æ•° [å¤©]',
        'fcf': 'è‡ªç”±ç°é‡‘æµ (FCF) [äº¿]',
        'cfo_to_net_income': 'å‡€ç°æ¯” (CFO/NetIncome)',
        'dividend_payout_ratio': 'åˆ†çº¢ç‡ (Payout Ratio) [%]',
        'dividend_per_share': 'æ¯è‚¡åˆ†çº¢ (DPS) [å…ƒ]',
        'dividend_total': 'åˆ†çº¢æ€»é¢ [äº¿]',
        'eps_basic': 'åŸºæœ¬æ¯è‚¡æ”¶ç›Š (EPS) [å…ƒ]',
        'eps_ttm': 'æ»šåŠ¨æ¯è‚¡æ”¶ç›Š (EPS-TTM) [å…ƒ]',
        'bps': 'æ¯è‚¡å‡€èµ„äº§ (BPS) [å…ƒ]',
        
        # åŸå§‹æŠ¥è¡¨ - åˆ©æ¶¦è¡¨
        'revenue': 'è¥ä¸šæ”¶å…¥ [äº¿]',
        'cost_of_revenue': 'è¥ä¸šæˆæœ¬ [äº¿]',
        'gross_profit': 'æ¯›åˆ© [äº¿]',
        'selling_expenses': 'é”€å”®è´¹ç”¨ [äº¿]',
        'admin_expenses': 'ç®¡ç†è´¹ç”¨ [äº¿]',
        'rd_expenses': 'ç ”å‘è´¹ç”¨ [äº¿]',
        'financial_expenses': 'è´¢åŠ¡è´¹ç”¨ [äº¿]',
        'income_tax_expenses': 'æ‰€å¾—ç¨è´¹ç”¨ [äº¿]', # æ–°å¢
        'investment_income': 'æŠ•èµ„æ”¶ç›Š [äº¿]',
        'operating_income': 'è¥ä¸šåˆ©æ¶¦ [äº¿]',
        'total_profit': 'åˆ©æ¶¦æ€»é¢ [äº¿]',
        'net_income': 'å‡€åˆ©æ¶¦ [äº¿]',
        'net_income_parent': 'å½’æ¯å‡€åˆ©æ¶¦ [äº¿]',
        'net_income_deducted': 'æ‰£éå‡€åˆ©æ¶¦ [äº¿]',
        
        # èµ„äº§è´Ÿå€ºè¡¨
        'total_assets': 'æ€»èµ„äº§ [äº¿]',
        'current_assets': 'æµåŠ¨èµ„äº§ [äº¿]',      # æ–°å¢
        'non_current_assets': 'éæµåŠ¨èµ„äº§ [äº¿]',  # æ–°å¢
        'total_liabilities': 'æ€»è´Ÿå€º [äº¿]',
        'current_liabilities': 'æµåŠ¨è´Ÿå€º [äº¿]',   # æ–°å¢
        'non_current_liabilities': 'éæµåŠ¨è´Ÿå€º [äº¿]', # æ–°å¢
        'total_equity': 'è‚¡ä¸œæƒç›Š [äº¿]',
        'share_capital': 'è‚¡æœ¬ [äº¿]',          # æ–°å¢
        'retained_earnings': 'æœªåˆ†é…åˆ©æ¶¦ [äº¿]',   # æ–°å¢
        'cash_equivalents': 'è´§å¸èµ„é‡‘ [äº¿]',
        'accounts_receivable': 'åº”æ”¶è´¦æ¬¾ [äº¿]',
        'inventory': 'å­˜è´§ [äº¿]',
        'fixed_assets': 'å›ºå®šèµ„äº§ [äº¿]',
        'intangible_assets': 'æ— å½¢èµ„äº§ [äº¿]',     # æ–°å¢
        'goodwill': 'å•†èª‰ [äº¿]',
        'short_term_debt': 'çŸ­æœŸå€Ÿæ¬¾ [äº¿]',
        'long_term_debt': 'é•¿æœŸå€Ÿæ¬¾ [äº¿]',
        'accounts_payable': 'åº”ä»˜è´¦æ¬¾ [äº¿]',
        'contract_liabilities': 'åˆåŒè´Ÿå€º [äº¿]',
        
        # ç°é‡‘æµé‡è¡¨
        'cfo_net': 'ç»è¥ç°é‡‘æµå‡€é¢ [äº¿]',
        'cfi_net': 'æŠ•èµ„ç°é‡‘æµå‡€é¢ [äº¿]',
        'cff_net': 'ç­¹èµ„ç°é‡‘æµå‡€é¢ [äº¿]',
        'net_cash_flow': 'ç°é‡‘å‡€å¢åŠ é¢ [äº¿]',    # æ–°å¢
        'capex': 'èµ„æœ¬å¼€æ”¯ [äº¿]',
        'cash_paid_for_dividends': 'åˆ†çº¢æ”¯ä»˜ç°é‡‘ [äº¿]'
    }

    # --- 6. é«˜äº®æ ·å¼å‡½æ•° ---
    def highlight_conflicts(df_display, df_source):
        """
        df_display: è½¬ç½®åçš„ç”¨äºæ˜¾ç¤ºçš„ DataFrame (è¡Œæ˜¯å­—æ®µï¼Œåˆ—æ˜¯æŠ¥å‘ŠæœŸ)
        df_source: åŸå§‹çš„ DataFrame (è¡Œæ˜¯æŠ¥å‘ŠæœŸï¼ŒåŒ…å« validation_details)
        """
        # åˆ›å»ºä¸€ä¸ªç©ºçš„æ ·å¼ DataFrameï¼Œé»˜è®¤æ— æ ·å¼
        df_style = pd.DataFrame('', index=df_display.index, columns=df_display.columns)
        
        # éå†æ¯ä¸€åˆ—ï¼ˆå³æ¯ä¸€ä¸ªæŠ¥å‘ŠæœŸï¼‰
        for col_name in df_display.columns:
            # æ‰¾åˆ°å¯¹åº”çš„æºæ•°æ®è¡Œ
            # col_name å¯èƒ½æ˜¯ "2023A" æˆ– "2023A âŒ"
            # æˆ‘ä»¬éœ€è¦é€šè¿‡ report_name æ‰¾åˆ°å¯¹åº”çš„è¡Œ
            source_row = df_source[df_source['report_name'] == col_name]
            
            if not source_row.empty:
                details_json = source_row.iloc[0].get('validation_details')
                if details_json:
                    try:
                        details = json.loads(details_json)
                        # æ‰¾å‡ºæœ‰å†²çªçš„å­—æ®µ
                        conflict_fields = [k for k, v in details.items() if v.get('status') == 'CONFLICT']
                        
                        # éå†æ˜¾ç¤ºè¡¨æ ¼çš„æ¯ä¸€è¡Œï¼ˆå³æ¯ä¸€ä¸ªå­—æ®µï¼‰
                        for idx in df_display.index:
                            # idx æ˜¯ä¸­æ–‡æ˜¾ç¤ºåï¼Œå¦‚ "è¥ä¸šæ”¶å…¥ [äº¿]"
                            # æˆ‘ä»¬éœ€è¦åå‘æ˜ å°„å›è‹±æ–‡å­—æ®µåï¼Œæˆ–è€…åœ¨ field_map é‡Œæ‰¾
                            # ç®€å•èµ·è§ï¼Œæˆ‘ä»¬æ£€æŸ¥ field_map çš„ value æ˜¯å¦åŒ…å« idx
                            
                            original_field = None
                            for k, v in field_map.items():
                                if v == idx:
                                    original_field = k
                                    break
                            
                            if original_field and original_field in conflict_fields:
                                # æ ‡è®°å†²çªï¼šèƒŒæ™¯æ·¡çº¢ï¼Œæ–‡å­—çº¢è‰²åŠ ç²—
                                df_style.loc[idx, col_name] = 'background-color: #ffe6e6; color: #d9534f; font-weight: bold;'
                                
                    except:
                        pass
        return df_style

    # --- 7. æ•°æ®å±•ç¤º ---
    
    # 7.1 æ ¸å¿ƒæŒ‡æ ‡
    st.subheader("ğŸ“ˆ æ ¸å¿ƒè´¢åŠ¡æŒ‡æ ‡")
    df_metrics = transpose_df(df_derived)
    # æ˜ å°„è¡Œå
    df_metrics.index = df_metrics.index.map(lambda x: field_map.get(x, x))
    # æ ¼å¼åŒ– (å¤„ç†ç©ºå€¼)
    st.dataframe(df_metrics.style.format("{:.2f}", na_rep="-"), height=400)

    # 7.2 åŸå§‹è´¢åŠ¡æŠ¥è¡¨ (å…¨é‡æ•°æ®)
    st.subheader("ğŸ“„ åŸå§‹è´¢åŠ¡æŠ¥è¡¨ (Raw Data)")
    
    # å®šä¹‰æ˜ å°„å­—å…¸ (ç”¨äºåœ¨ UI ä¸Šæ ‡æ³¨æ ¸å¿ƒå˜é‡)
    # æ³¨æ„ï¼šè¿™é‡Œåªæ˜¯ä¸ºäº†æ˜¾ç¤ºï¼Œå®é™…é€»è¾‘åœ¨ Fetcher é‡Œ
    # æˆ‘ä»¬åšä¸€ä¸ªç®€å•çš„åå‘æŸ¥æ‰¾ï¼š åŸå§‹ä¸­æ–‡ -> å†…éƒ¨è‹±æ–‡
    hk_mapping_display = {}
    # æ¬è¿è‡ª hk_share.py çš„æ˜ å°„é€»è¾‘
    raw_map = {
        'revenue': ['è¥ä¸šé¢', 'è¥ä¸šæ”¶å…¥', 'è¥ä¸šæ€»æ”¶å…¥', 'æ”¶å…¥'],
        'gross_profit': ['æ¯›åˆ©'],
        'net_income_parent': ['æœ¬å…¬å¸æ‹¥æœ‰äººåº”å æº¢åˆ©', 'å½’å±äºæ¯å…¬å¸è‚¡ä¸œçš„å‡€åˆ©æ¶¦', 'å½’æ¯å‡€åˆ©æ¶¦'],
        'net_income': ['å¹´åº¦æº¢åˆ©', 'å‡€åˆ©æ¶¦'],
        'eps_basic': ['åŸºæœ¬æ¯è‚¡ç›ˆåˆ©', 'åŸºæœ¬æ¯è‚¡æ”¶ç›Š'],
        'rd_expenses': ['ç ”ç©¶åŠå¼€å‘æˆæœ¬', 'ç ”å‘è´¹ç”¨'],
        'total_assets': ['èµ„äº§æ€»å€¼', 'èµ„äº§åˆè®¡', 'æ€»èµ„äº§'],
        'total_liabilities': ['è´Ÿå€ºæ€»é¢', 'è´Ÿå€ºåˆè®¡', 'æ€»è´Ÿå€º'],
        'total_equity': ['æœ¬å…¬å¸æ‹¥æœ‰äººåº”å æƒç›Š', 'æƒç›Šåˆè®¡', 'è‚¡ä¸œæƒç›Šåˆè®¡'],
        'cash_equivalents': ['ç°é‡‘åŠç°é‡‘ç­‰ä»·ç‰©', 'è´§å¸èµ„é‡‘'],
        'cfo_net': ['ç»è¥ä¸šåŠ¡ç°é‡‘å‡€é¢', 'ç»è¥æ´»åŠ¨äº§ç”Ÿçš„ç°é‡‘æµé‡å‡€é¢'],
        'capex': ['è´­å»ºå›ºå®šèµ„äº§', 'è´­ä¹°ç‰©ä¸šã€å‚æˆ¿åŠè®¾å¤‡']
    }
    for internal_key, raw_list in raw_map.items():
        for raw_name in raw_list:
            hk_mapping_display[raw_name] = internal_key

    if 'raw_data' in df_raw.columns and not df_raw['raw_data'].isna().all():
        # è§£ææ‰€æœ‰è¡Œçš„ JSON
        all_rows = []
        for idx, row in df_raw.iterrows():
            if row['raw_data']:
                try:
                    row_dict = json.loads(row['raw_data'])
                    # åŠ ä¸ŠæŠ¥å‘ŠæœŸä½œä¸ºç¬¬ä¸€åˆ—
                    row_dict['report_period'] = row['report_period']
                    all_rows.append(row_dict)
                except:
                    pass
        
        if all_rows:
            df_full = pd.DataFrame(all_rows)
            # æŠŠ report_period è®¾ä¸ºç´¢å¼•
            if 'report_period' in df_full.columns:
                df_full.set_index('report_period', inplace=True)
            
            # --- æ§åˆ¶é€‰é¡¹ ---
            col1, col2 = st.columns(2)
            with col1:
                unit_opt = st.radio("å•ä½", ["åŸå§‹å€¼ (å…ƒ)", "äº¿"], horizontal=True, key="full_data_unit")
            with col2:
                transpose_opt = st.checkbox("è½¬ç½®è¡¨æ ¼ (æ—¶é—´æ¨ªè½´)", value=True, key="full_data_transpose")
            
            # --- æ•°æ®å¤„ç† ---
            # 1. å•ä½è½¬æ¢
            if unit_opt == "äº¿":
                for col in df_full.columns:
                    df_full[col] = pd.to_numeric(df_full[col], errors='ignore')
                    if pd.api.types.is_numeric_dtype(df_full[col]):
                        if df_full[col].abs().median() > 10000:
                            df_full[col] = df_full[col] / 1e8
            
            # 2. è½¬ç½®
            if transpose_opt:
                df_display = df_full.T
                # åœ¨è½¬ç½®åçš„ç´¢å¼•(å­—æ®µå)ä¸Šæ·»åŠ æ ‡æ³¨
                new_index = []
                for idx in df_display.index:
                    internal_name = hk_mapping_display.get(idx)
                    if internal_name:
                        new_index.append(f"{idx} ({internal_name})")
                    else:
                        new_index.append(idx)
                df_display.index = new_index
            else:
                df_display = df_full
                # å¦‚æœä¸è½¬ç½®ï¼Œåˆ—åæ·»åŠ æ ‡æ³¨
                new_cols = []
                for col in df_display.columns:
                    internal_name = hk_mapping_display.get(col)
                    if internal_name:
                        new_cols.append(f"{col} ({internal_name})")
                    else:
                        new_cols.append(col)
                df_display.columns = new_cols

            # å±•ç¤º
            st.dataframe(df_display, height=600)
            st.caption(f"å…±åŒ…å« {len(df_full.columns)} ä¸ªåŸå§‹å­—æ®µã€‚æ‹¬å·å†…ä¸ºç³»ç»Ÿè¯†åˆ«çš„æ ¸å¿ƒå˜é‡åã€‚")
    else:
        st.info("æš‚æ— åŸå§‹æ•°æ®ï¼Œè¯·ç‚¹å‡»ä¾§è¾¹æ 'å¼ºåˆ¶æ›´æ–°æ•°æ®'ã€‚")

else:
    st.warning("æœªæ‰¾åˆ°æ•°æ®ã€‚")
